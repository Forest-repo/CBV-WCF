# When Complementarity Meets Consistency: Weighted Collaboration Fusion Constrained by Consistency Between Views for Multi-View Urban Scene Classification
this is "CBV-WCF" paper
# Introduction
1. This paper proposes a novel multiple-input multiple-output architecture for multi-view scene classification, which is highly flexible and widely applicable. It can classify both dual-view scenes and single-view direct reasoning. Fields offer new ideas and additional solutions.
2. Considering the essential characteristics and connections of multi-view data, and inspired by the idea of "people flock together, things are divided into groups", a CIC module is proposed to constrain the consistency information between the air and ground views, and in a specific feature space, the The distance between similar images under different viewing angles is shortened, and the distance between heterogeneous images is extended. After forming a priori condition for "clustering" between similar views, it will be easier to classify scenes, and at the same time improve the similarity between classes to a certain extent. Due to the disadvantages of gender and intra-class diversity, through clustering constraints, individual poor images will not be separated from the overall distribution of the category to which they belong, which improves the performance of scene classification.
3. Explored the research on feature-level fusion between multiple modalities, and proposed the weighted collaborative fusion WCF module to fully mine and effectively fuse the potential complementary information between different views. Starting from the two branches, the independence and independence of the original view feature extraction are guaranteed. Integrity, and also fully self-adaptively fuse the complementary features required by the view, significantly improve the performance of scene classification after fusion at the feature level, and demonstrate the use of feature fusion of multi-source multi-modal data for urban land classification. possibility and inspiration.
4. A comprehensive evaluation was carried out on two publicly available multi-view datasets, which verified the effectiveness and robustness of this framework from the practical level, and significantly improved the performance of scene classification under single-view and dual-view. The ideas and logic brought are helpful for further research on multimodal tasks, and are beneficial to the modeling of multimodal tasks related to computer vision in the future.

# Dataset
[Download the Datasets](http://www.patreo.dcc.ufmg.br/multi-view-datasets/)

# Citation:
If you find our work is useful, please kindly cite the following: BibTex
